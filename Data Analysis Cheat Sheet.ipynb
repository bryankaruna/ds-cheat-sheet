{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "\n",
    "#controls number of columns being printed\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "#read CSV\n",
    "df = pd.read_csv('', header='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set headers\n",
    "headers=[\"header_1\", \"header_2\", \"header_3\"]\n",
    "df.columns = headers\n",
    "\n",
    "#get headers\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first 5 rows\n",
    "df.head()\n",
    "\n",
    "#check last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"automobile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistical summary\n",
    "df.describe()\n",
    "#more advance summary\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more concise summary\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "How to deal with missing data?\n",
    "##### drop data\n",
    "- drop the whole row\n",
    "- drop the whole column\n",
    "\n",
    "##### replace data\n",
    "- replace it by mean\n",
    "- replace it by frequency\n",
    "- replace it based on other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data check\n",
    "missing_data = df.isnull()\n",
    "missing_data.head()\n",
    "\n",
    "#missing data counter\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")  \n",
    "\n",
    "#isna.count\n",
    "df.isna().sum()\n",
    "    \n",
    "# dropna\n",
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
    "\n",
    "#change column types then get mean\n",
    "avg_norm_loss = df[\"normalized-losses\"].astype(float).mean(axis=0)\n",
    "\n",
    "#replace NaN\n",
    "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)\n",
    "\n",
    "#to see which values are present in a particular column\n",
    "df[\"num-of-doors\"].value_counts()\n",
    "#get the most frequency values showed\n",
    "df[\"num-of-doors\"].value_counts().idxmax()\n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)\n",
    "\n",
    "#reset index after dropping rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing types\n",
    "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
    "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
    "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
    "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")\n",
    "\n",
    "#last check\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename cplumn\n",
    "df[\"highway-mpg\"] = 235/df[\"highway-mpg\"]\n",
    "df.rename(columns={'\"highway-mpg\"': 'highway-L/100km'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Feature Scaling\n",
    "df[\"length\"] = df[\"length\"]/df[\"length\"].max()\n",
    "#Min Max Feature Scaling\n",
    "df[\"length\"] = (df[\"length\"]-df[\"length\"].min())/(df[\"length\"].max()-df[\"length\"].min())\n",
    "#Z-Score\n",
    "df[\"length\"] = (df[\"length\"]-df[\"length\"].mean())/df[\"length\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Histogram Code\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "plt.pyplot.hist(df[\"price\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"price\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"price bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping values\n",
    "bins = np.linspace(min(df[\"price\"]), max(df[\"price\"]), 4)\n",
    "group_names = [\"Low\", \"Medium\", \"High\"]\n",
    "df[\"price-binned\"] = pd.cut(df[\"price\"], bins, labels=group_names, include_lowest=True)\n",
    "df[[\"price\", \"price-binned\"]].head()\n",
    "#apply histogram but with the binned version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to 0,1 values\n",
    "dummy_variable_1 = pd.get_dummies(df['fuel'])\n",
    "dummy_variable_1.rename(columns={'fuel-type-diesel':'gas', 'fuel-type-diesel':'diesel'}, inplace=True)\n",
    "dummy_variable_1.head()\n",
    "\n",
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "df = pd.concat([df, dummy_variable_1], axis=1)\n",
    "\n",
    "# drop original column \"fuel-type\" from \"df\"\n",
    "df.drop(\"fuel-type\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fast statistic summary\n",
    "df.describe()\n",
    "\n",
    "# get count number\n",
    "drive_wheels_counts = df[\"drive-wheels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIPTIVE ANALYSIS\n",
    "#1. boxplot to see distribution and outlier\n",
    "#2. scatter plot to see relationship between 2 variables (predictor, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUPING DATA\n",
    "df_test = df[['drive-wheels','body-style','price']]\n",
    "df_grp = df_test.groupby(['drive-wheels', 'body-style'], as_index=False).mean()\n",
    "df_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIVOT\n",
    "df_pivot = df_grp.pivot(index='drive-wheels', columns='body-style')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pandas_pivot1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "%%capture\n",
    "! pip install seaborn\n",
    "\n",
    "#import\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap = see relationship in multiple variables\n",
    "plt.pcolor(df_pivot, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./heatmap1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolor(grouped_pivot, cmap='RdBu')\n",
    "\n",
    "#label names\n",
    "row_labels = grouped_pivot.columns.levels[1]\n",
    "col_labels = grouped_pivot.index\n",
    "\n",
    "#move ticks and labels to the center\n",
    "ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "#insert labels\n",
    "ax.set_xticklabels(row_labels, minor=False)\n",
    "ax.set_yticklabels(col_labels, minor=False)\n",
    "\n",
    "#rotate label if too long\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./heatmap2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA(Analysis of Variance) = finding correlation between different groups of a categorical variable\n",
    "#ex. Average price of different vehicle makes.\n",
    "#returns:\n",
    "#1. F-test score = calculates the reatio of variation within each of the sample group means. Bigger score = highly correlate\n",
    "#2. p-value > 0.05 means null hyphoteses is not accepted. Score < 0.5 = good\n",
    "df_anova = df[[\"make\",\"price\"]]\n",
    "grouped_anova = df_anova.groupby([\"make\"])\n",
    "\n",
    "#anova components:\n",
    "#1. get group => to get values of the method group\n",
    "grouped_anova.get_group('subaru')['price']\n",
    "#2. f_oneway => get f-test score and p-value\n",
    "anova_results_1 = stats.f_oneway(grouped_anova.get_group(\"honda\")[\"price\"], grouped_anova.get_group(\"subaru\")[\"price\"], grouped_anova.get_group(\"mercedes\")[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation = measure to what extent different variables are interdependent\n",
    "#Correlation doens't imply causation\n",
    "#ex:\n",
    "#1. Lung cancer -> smoking\n",
    "#2. rain -> umbrella\n",
    "#returns: positive, negative, weak, strong, no correlation\n",
    "\n",
    "#THIS IS FOR NUMERICAL VARIABLES\n",
    "sns.regplot(x=\"engine-size\", y=\"price\", data=df)\n",
    "plt.ylim(0,)\n",
    "\n",
    "# seek correlation value after visualisation:\n",
    "df[['feature','target']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS FOR CATEGORICAL VARIABLES (object/int data types allowed)\n",
    "#use boxplot. Prevent overlapping boxes\n",
    "sns.boxplot(x=\"body-style\", y=\"price\", data=df)\n",
    "\n",
    "#describe for categorical\n",
    "df.describe(include=['object'])\n",
    "\n",
    "#check how many units of each variable we have. Note: we are not using double bracket, value_counts works for pandas series (not pandas df)\n",
    "engine_loc_counts = df['engine-location'].value_counts().to_frame()\n",
    "engine_loc_counts.rename(columns={'engine-location': 'value_counts'}, inplace=True)\n",
    "engine_loc_counts.index.name = 'engine-location'\n",
    "engine_loc_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./value_count.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another correlation implementation: Pearson Correlation\n",
    "#Aim: measure the strength of the correlation between two features.\n",
    "#consists of:\n",
    "#1. correlation coefficient: linearity test. (+1) strong positive relationship; (-1) strong negative relationship; (0) no relationship\n",
    "#2. p-value: statistical significance test. The smaller the better (threshold < 0.05) else (>0.1) no correlation.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "pearson_coef, p_value = stats.pearsonr(df['housepower'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic of Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see different categories\n",
    "df['drive-wheels'].unique()\n",
    "\n",
    "#assign to variables\n",
    "df_group_one = df[['drive-wheels','body-style','price']]\n",
    "\n",
    "#grouping results\n",
    "df_group_one = df_group_one.groupby(['drive-wheels'], as_index=False).mean()\n",
    "df_group_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./groupby.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping multiple variables is also alllowed\n",
    "df_gptest = df[['drive-wheels','body-style','price']]\n",
    "grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()\n",
    "grouped_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./groupby2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVES, you'll never be wrong with pivot tables\n",
    "grouped_pivot = grouped_test1.pivot(index='drive-wheels',columns='body-style')\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pivot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fill the missing values with 0\n",
    "grouped_pivot = grouped_pivot.fillna(0)\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y= b0 + b1x\n",
    "- y = target / dependent variable\n",
    "- x = predictor / independent variable\n",
    "- b0 = intercept\n",
    "- b1 = slope\n",
    "\n",
    "noise = small random value added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose model\n",
    "lm = LinearRegression()\n",
    "lm\n",
    "\n",
    "#choose dependent & independent variables\n",
    "X = df[['highway-mpg']]\n",
    "y = df['price']\n",
    "\n",
    "#start train\n",
    "lm.fit(X,y)\n",
    "\n",
    "#predict\n",
    "Yhat=lm.predict(X)\n",
    "Yhat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check intercept and slope\n",
    "lm.intercept_\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Yhat = a + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\n",
    "y = df['price']\n",
    "lm.fit(X,y)\n",
    "\n",
    "lm.intercept_\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation with Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the visualization package: seaborn\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize regression plot\n",
    "width = 12\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./regression_plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What we can see here?\n",
    "how scattered the data points around the regression line? <- variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize residual plot => a good way to visualize the variance of the data\n",
    "- what is residual? the difference between the observed value (y) and the predicted value (Yhat).\n",
    "- when we look at a regression plot, the residual is the distance from the data point to the fitted regression line.\n",
    "\n",
    "- residual plot?? graph that shows the residuals on the vertical y-axis and the independent variable on horizontal x-axis.\n",
    "\n",
    "- what to see?? <b>look at the spread of the residuals.</b> If the points in a residual plot are randomly spread out, then a linear model is appropriate for the data.\n",
    "\n",
    "- why?? randomly spread out residuals means that the variance is constant, and the linear model is a good fit for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 12\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "sns.residplot(df['highway-mpg'], df['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./residual_plot.png\">\n",
    "\n",
    "#### What is the plot tell us?\n",
    "We can see from this residual plot that the residuals are not randomly spread around the x-axis, which leads us to believe that maybe a non-linear model is more appropriate for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Linear Regression\n",
    "We can't visualize it with regression or residual plot <b> rather use the distribution of the fitted values and the actual values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a prediction\n",
    "Y_hat = lm.predict(Z)\n",
    "\n",
    "#visualize\n",
    "plt.figure(figsize=(10, 12))\n",
    "\n",
    "ax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(Yhat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price (in dollars)')\n",
    "plt.ylabel('Proportion of Cars')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./visual_mlr.png\">\n",
    "\n",
    "We can see that the fitted values are reasonably close to the actual values, since the two distributions overlap a bit. However, there is definitely some room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression and Pipelines\n",
    "- Polynomial regression is a <b>particular case</b> of the general <b>linear regression or multiple linear regression models.</b>\n",
    "- We get non-linear relationships by <i>squaring</i> or <i>setting higher-order terms of the predictor variables</i>.\n",
    "\n",
    "* Different orders of polynomial regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Quadratic - 2nd order</b></center>\n",
    "$$\n",
    "Yhat = a + b_1 X^2 +b_2 X^2 \n",
    "$$\n",
    "\n",
    "\n",
    "<center><b>Cubic - 3rd order</b></center>\n",
    "$$\n",
    "Yhat = a + b_1 X^2 +b_2 X^2 +b_3 X^3\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "<center><b>Higher order</b>:</center>\n",
    "$$\n",
    "Y = a + b_1 X^2 +b_2 X^2 +b_3 X^3 ....\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We saw earlier that a linear model did not provide the best fit while using highway-mpg as the predictor variable. Let's see if we can try fitting a polynomial model to the data instead.</p>\n",
    "<p>We will use the following function to plot the data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
    "    x_new = np.linspace(15, 55, 100)\n",
    "    y_new = model(x_new)\n",
    "\n",
    "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
    "    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
    "    fig = plt.gcf()\n",
    "    plt.xlabel(Name)\n",
    "    plt.ylabel('Price of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "# lets get the variables\n",
    "x = df['highway-mpg']\n",
    "y = df['price']\n",
    "\n",
    "# Here we use a polynomial of the 3rd order (cubic) \n",
    "f = np.polyfit(x, y, 3)\n",
    "p = np.poly1d(f)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./polynomial_function.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you want to see np.polyfit result\n",
    "np.polyfit(x, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./polynomial_function2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot the function\n",
    "PlotPolly(p, x, y, 'highway-mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./polynomial_cubic_res.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Analytical Expression for Multiple Polynomial\n",
    "For example for second order (degree=2) polynomial with 2 variables is given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Yhat = a + b_1 X_1 +b_2 X_2 +b_3 X_1 X_2+b_4 X_1^2+b_5 X_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# we create a polynomial object for degree 2\n",
    "pr=PolynomialFeatures(degree=2)\n",
    "pr\n",
    "\n",
    "#fit\n",
    "Z_pr=pr.fit_transform(Z)\n",
    "\n",
    "#original data shape (201,4)\n",
    "Z.shape\n",
    "\n",
    "#fitted data shape (201,15)\n",
    "Z_pr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "- Data pipelines simplify the steps of processing the data. \n",
    "- We use the module Pipeline to create a pipeline. \n",
    "- We also use StandardScaler as a step in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline(Input)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(Z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypipe=pipe.predict(Z)\n",
    "ypipe[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure for In-Sample Evaluation\n",
    "When evaluating our models, not only visualize the result but also want to measure quantitatively how accurate the model is.\n",
    "<p>Two very important measures that are often used in Statistics to determine the accuracy of a model are:</p>\n",
    "<ul>\n",
    "    <li><b>R^2 / R-squared</b> => or Coefficient of determination, is a measure to indicate how close the data is to the fitted regression line. The value is in percentage of variation of the target variable (y) that's explained by a linear model.</li>\n",
    "    <li><b>Mean Squared Error (MSE)</b> => measures the average of the squares of errors, that is, the difference between actual value (y) and the estimated value (ŷ)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2\n",
    "lm.fit(df[['horsepower_fit']], df['price'])\n",
    "# Find the R^2\n",
    "print('The R-square is: ', lm.score(X, Y)) # 0.760xxxx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R^2 alternatives\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y, p(x))\n",
    "print('The R-square value is: ', r_squared) # <- the close to -1/1 the better, the closer to zero = bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say 76% of the variation of the price is explained by the simple linear model \"horsepower_fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets calculate the MSE\n",
    "Yhat=lm.predict(X)\n",
    "print('The output of the first four predicted value is: ', Yhat[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(df['price'], Yhat)\n",
    "print('The mean square error of price and predicted value is: ', mse) #15021126.025174143 <- the smaller the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Decision Making\n",
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new input\n",
    "new_input=np.arange(1, 100, 1).reshape(-1, 1)\n",
    "\n",
    "#fit the model\n",
    "lm.fit(X, Y)\n",
    "lm\n",
    "\n",
    "#produce a prediction\n",
    "yhat=lm.predict(new_input)\n",
    "yhat[0:5]\n",
    "\n",
    "#plot a data\n",
    "plt.plot(new_input, yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"prediction_to_predict.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Making\n",
    "Even tho multiple models usually results better, we need to check the MSE and R^2 to convinced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
