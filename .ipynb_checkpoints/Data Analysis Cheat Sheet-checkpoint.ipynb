{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "\n",
    "#controls number of columns being printed\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "#read CSV\n",
    "df = pd.read_csv('', header='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set headers\n",
    "headers=[\"header_1\", \"header_2\", \"header_3\"]\n",
    "df.columns = headers\n",
    "\n",
    "#get headers\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first 5 rows\n",
    "df.head()\n",
    "\n",
    "#check last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"automobile.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get statistical summary\n",
    "df.describe()\n",
    "#more advance summary\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more concise summary\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "How to deal with missing data?\n",
    "##### drop data\n",
    "- drop the whole row\n",
    "- drop the whole column\n",
    "\n",
    "##### replace data\n",
    "- replace it by mean\n",
    "- replace it by frequency\n",
    "- replace it based on other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data check\n",
    "missing_data = df.isnull()\n",
    "missing_data.head()\n",
    "\n",
    "#missing data counter\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")  \n",
    "\n",
    "#isna.count\n",
    "df.isna().sum()\n",
    "    \n",
    "# dropna\n",
    "df.dropna(subset=[\"price\"], axis=0, inplace=True)\n",
    "\n",
    "#change column types then get mean\n",
    "avg_norm_loss = df[\"normalized-losses\"].astype(float).mean(axis=0)\n",
    "\n",
    "#replace NaN\n",
    "df[\"normalized-losses\"].replace(np.nan, avg_norm_loss, inplace=True)\n",
    "\n",
    "#to see which values are present in a particular column\n",
    "df[\"num-of-doors\"].value_counts()\n",
    "#get the most frequency values showed\n",
    "df[\"num-of-doors\"].value_counts().idxmax()\n",
    "df[\"num-of-doors\"].replace(np.nan, \"four\", inplace=True)\n",
    "\n",
    "#reset index after dropping rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing types\n",
    "df[[\"bore\", \"stroke\"]] = df[[\"bore\", \"stroke\"]].astype(\"float\")\n",
    "df[[\"normalized-losses\"]] = df[[\"normalized-losses\"]].astype(\"int\")\n",
    "df[[\"price\"]] = df[[\"price\"]].astype(\"float\")\n",
    "df[[\"peak-rpm\"]] = df[[\"peak-rpm\"]].astype(\"float\")\n",
    "\n",
    "#last check\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename cplumn\n",
    "df[\"highway-mpg\"] = 235/df[\"highway-mpg\"]\n",
    "df.rename(columns={'\"highway-mpg\"': 'highway-L/100km'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Feature Scaling\n",
    "df[\"length\"] = df[\"length\"]/df[\"length\"].max()\n",
    "#Min Max Feature Scaling\n",
    "df[\"length\"] = (df[\"length\"]-df[\"length\"].min())/(df[\"length\"].max()-df[\"length\"].min())\n",
    "#Z-Score\n",
    "df[\"length\"] = (df[\"length\"]-df[\"length\"].mean())/df[\"length\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Histogram Code\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "plt.pyplot.hist(df[\"price\"])\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"price\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"price bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping values\n",
    "bins = np.linspace(min(df[\"price\"]), max(df[\"price\"]), 4)\n",
    "group_names = [\"Low\", \"Medium\", \"High\"]\n",
    "df[\"price-binned\"] = pd.cut(df[\"price\"], bins, labels=group_names, include_lowest=True)\n",
    "df[[\"price\", \"price-binned\"]].head()\n",
    "#apply histogram but with the binned version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to 0,1 values\n",
    "dummy_variable_1 = pd.get_dummies(df['fuel'])\n",
    "dummy_variable_1.rename(columns={'fuel-type-diesel':'gas', 'fuel-type-diesel':'diesel'}, inplace=True)\n",
    "dummy_variable_1.head()\n",
    "\n",
    "# merge data frame \"df\" and \"dummy_variable_1\" \n",
    "df = pd.concat([df, dummy_variable_1], axis=1)\n",
    "\n",
    "# drop original column \"fuel-type\" from \"df\"\n",
    "df.drop(\"fuel-type\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fast statistic summary\n",
    "df.describe()\n",
    "\n",
    "# get count number\n",
    "drive_wheels_counts = df[\"drive-wheels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIPTIVE ANALYSIS\n",
    "#1. boxplot to see distribution and outlier\n",
    "#2. scatter plot to see relationship between 2 variables (predictor, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUPING DATA\n",
    "df_test = df[['drive-wheels','body-style','price']]\n",
    "df_grp = df_test.groupby(['drive-wheels', 'body-style'], as_index=False).mean()\n",
    "df_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIVOT\n",
    "df_pivot = df_grp.pivot(index='drive-wheels', columns='body-style')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pandas_pivot1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install\n",
    "%%capture\n",
    "! pip install seaborn\n",
    "\n",
    "#import\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap = see relationship in multiple variables\n",
    "plt.pcolor(df_pivot, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./heatmap1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolor(grouped_pivot, cmap='RdBu')\n",
    "\n",
    "#label names\n",
    "row_labels = grouped_pivot.columns.levels[1]\n",
    "col_labels = grouped_pivot.index\n",
    "\n",
    "#move ticks and labels to the center\n",
    "ax.set_xticks(np.arange(grouped_pivot.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(grouped_pivot.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "#insert labels\n",
    "ax.set_xticklabels(row_labels, minor=False)\n",
    "ax.set_yticklabels(col_labels, minor=False)\n",
    "\n",
    "#rotate label if too long\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "fig.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./heatmap2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOVA(Analysis of Variance) = finding correlation between different groups of a categorical variable\n",
    "#ex. Average price of different vehicle makes.\n",
    "#returns:\n",
    "#1. F-test score = calculates the reatio of variation within each of the sample group means. Bigger score = highly correlate\n",
    "#2. p-value > 0.05 means null hyphoteses is not accepted. Score < 0.5 = good\n",
    "df_anova = df[[\"make\",\"price\"]]\n",
    "grouped_anova = df_anova.groupby([\"make\"])\n",
    "\n",
    "#anova components:\n",
    "#1. get group => to get values of the method group\n",
    "grouped_anova.get_group('subaru')['price']\n",
    "#2. f_oneway => get f-test score and p-value\n",
    "anova_results_1 = stats.f_oneway(grouped_anova.get_group(\"honda\")[\"price\"], grouped_anova.get_group(\"subaru\")[\"price\"], grouped_anova.get_group(\"mercedes\")[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation = measure to what extent different variables are interdependent\n",
    "#Correlation doens't imply causation\n",
    "#ex:\n",
    "#1. Lung cancer -> smoking\n",
    "#2. rain -> umbrella\n",
    "#returns: positive, negative, weak, strong, no correlation\n",
    "\n",
    "#THIS IS FOR NUMERICAL VARIABLES\n",
    "sns.regplot(x=\"engine-size\", y=\"price\", data=df)\n",
    "plt.ylim(0,)\n",
    "\n",
    "# seek correlation value after visualisation:\n",
    "df[['feature','target']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS FOR CATEGORICAL VARIABLES (object/int data types allowed)\n",
    "#use boxplot. Prevent overlapping boxes\n",
    "sns.boxplot(x=\"body-style\", y=\"price\", data=df)\n",
    "\n",
    "#describe for categorical\n",
    "df.describe(include=['object'])\n",
    "\n",
    "#check how many units of each variable we have. Note: we are not using double bracket, value_counts works for pandas series (not pandas df)\n",
    "engine_loc_counts = df['engine-location'].value_counts().to_frame()\n",
    "engine_loc_counts.rename(columns={'engine-location': 'value_counts'}, inplace=True)\n",
    "engine_loc_counts.index.name = 'engine-location'\n",
    "engine_loc_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./value_count.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another correlation implementation: Pearson Correlation\n",
    "#Aim: measure the strength of the correlation between two features.\n",
    "#consists of:\n",
    "#1. correlation coefficient: linearity test. (+1) strong positive relationship; (-1) strong negative relationship; (0) no relationship\n",
    "#2. p-value: statistical significance test. The smaller the better (threshold < 0.05) else (>0.1) no correlation.\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "pearson_coef, p_value = stats.pearsonr(df['housepower'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic of Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see different categories\n",
    "df['drive-wheels'].unique()\n",
    "\n",
    "#assign to variables\n",
    "df_group_one = df[['drive-wheels','body-style','price']]\n",
    "\n",
    "#grouping results\n",
    "df_group_one = df_group_one.groupby(['drive-wheels'], as_index=False).mean()\n",
    "df_group_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./groupby.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping multiple variables is also alllowed\n",
    "df_gptest = df[['drive-wheels','body-style','price']]\n",
    "grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()\n",
    "grouped_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./groupby2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVES, you'll never be wrong with pivot tables\n",
    "grouped_pivot = grouped_test1.pivot(index='drive-wheels',columns='body-style')\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pivot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fill the missing values with 0\n",
    "grouped_pivot = grouped_pivot.fillna(0)\n",
    "grouped_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y= b0 + b1x\n",
    "- y = target / dependent variable\n",
    "- x = predictor / independent variable\n",
    "- b0 = intercept\n",
    "- b1 = slope\n",
    "\n",
    "noise = small random value added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose model\n",
    "lm = LinearRegression()\n",
    "lm\n",
    "\n",
    "#choose dependent & independent variables\n",
    "X = df[['highway-mpg']]\n",
    "y = df['price']\n",
    "\n",
    "#start train\n",
    "lm.fit(X,y)\n",
    "\n",
    "#predict\n",
    "Yhat=lm.predict(X)\n",
    "Yhat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check intercept and slope\n",
    "lm.intercept_\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Yhat = a + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\n",
    "y = df['price']\n",
    "lm.fit(X,y)\n",
    "\n",
    "lm.intercept_\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation with Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the visualization package: seaborn\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize regression plot\n",
    "width = 12\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./regression_plot.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What we can see here?\n",
    "how scattered the data points around the regression line? <- variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize residual plot => a good way to visualize the variance of the data\n",
    "- what is residual? the difference between the observed value (y) and the predicted value (Yhat).\n",
    "- when we look at a regression plot, the residual is the distance from the data point to the fitted regression line.\n",
    "\n",
    "- residual plot?? graph that shows the residuals on the vertical y-axis and the independent variable on horizontal x-axis.\n",
    "\n",
    "- what to see?? <b>look at the spread of the residuals.</b> If the points in a residual plot are randomly spread out, then a linear model is appropriate for the data.\n",
    "\n",
    "- why?? randomly spread out residuals means that the variance is constant, and the linear model is a good fit for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 12\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "sns.residplot(df['highway-mpg'], df['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./residual_plot.png\">\n",
    "\n",
    "#### What is the plot tell us?\n",
    "We can see from this residual plot that the residuals are not randomly spread around the x-axis, which leads us to believe that maybe a non-linear model is more appropriate for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Linear Regression\n",
    "We can't visualize it with regression or residual plot <b> rather use the distribution of the fitted values and the actual values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a prediction\n",
    "Y_hat = lm.predict(Z)\n",
    "\n",
    "#visualize\n",
    "plt.figure(figsize=(10, 12))\n",
    "\n",
    "ax1 = sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(Yhat, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "\n",
    "plt.title('Actual vs Fitted Values for Price')\n",
    "plt.xlabel('Price (in dollars)')\n",
    "plt.ylabel('Proportion of Cars')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./visual_mlr.png\">\n",
    "\n",
    "We can see that the fitted values are reasonably close to the actual values, since the two distributions overlap a bit. However, there is definitely some room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression and Pipelines\n",
    "- Polynomial regression is a <b>particular case</b> of the general <b>linear regression or multiple linear regression models.</b>\n",
    "- We get non-linear relationships by <i>squaring</i> or <i>setting higher-order terms of the predictor variables</i>.\n",
    "\n",
    "* Different orders of polynomial regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Quadratic - 2nd order</b></center>\n",
    "$$\n",
    "Yhat = a + b_1 X^2 +b_2 X^2 \n",
    "$$\n",
    "\n",
    "\n",
    "<center><b>Cubic - 3rd order</b></center>\n",
    "$$\n",
    "Yhat = a + b_1 X^2 +b_2 X^2 +b_3 X^3\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "<center><b>Higher order</b>:</center>\n",
    "$$\n",
    "Y = a + b_1 X^2 +b_2 X^2 +b_3 X^3 ....\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We saw earlier that a linear model did not provide the best fit while using highway-mpg as the predictor variable. Let's see if we can try fitting a polynomial model to the data instead.</p>\n",
    "<p>We will use the following function to plot the data:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
    "    x_new = np.linspace(15, 55, 100)\n",
    "    y_new = model(x_new)\n",
    "\n",
    "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
    "    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
    "    fig = plt.gcf()\n",
    "    plt.xlabel(Name)\n",
    "    plt.ylabel('Price of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "# lets get the variables\n",
    "x = df['highway-mpg']\n",
    "y = df['price']\n",
    "\n",
    "# Here we use a polynomial of the 3rd order (cubic) \n",
    "f = np.polyfit(x, y, 3)\n",
    "p = np.poly1d(f)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./polynomial_function.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you want to see np.polyfit result\n",
    "np.polyfit(x, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./polynomial_function2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets plot the function\n",
    "PlotPolly(p, x, y, 'highway-mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./polynomial_cubic_res.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Analytical Expression for Multiple Polynomial\n",
    "For example for second order (degree=2) polynomial with 2 variables is given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Yhat = a + b_1 X_1 +b_2 X_2 +b_3 X_1 X_2+b_4 X_1^2+b_5 X_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# we create a polynomial object for degree 2\n",
    "pr=PolynomialFeatures(degree=2)\n",
    "pr\n",
    "\n",
    "#fit\n",
    "Z_pr=pr.fit_transform(Z)\n",
    "\n",
    "#original data shape (201,4)\n",
    "Z.shape\n",
    "\n",
    "#fitted data shape (201,15)\n",
    "Z_pr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "- Data pipelines simplify the steps of processing the data. \n",
    "- We use the module Pipeline to create a pipeline. \n",
    "- We also use StandardScaler as a step in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input=[('scale',StandardScaler()), ('polynomial', PolynomialFeatures(include_bias=False)), ('model',LinearRegression())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline(Input)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(Z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypipe=pipe.predict(Z)\n",
    "ypipe[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure for In-Sample Evaluation\n",
    "When evaluating our models, not only visualize the result but also want to measure quantitatively how accurate the model is.\n",
    "<p>Two very important measures that are often used in Statistics to determine the accuracy of a model are:</p>\n",
    "<ul>\n",
    "    <li><b>R^2 / R-squared</b> => or Coefficient of determination, is a measure to indicate how close the data is to the fitted regression line. The value is in percentage of variation of the target variable (y) that's explained by a linear model.</li>\n",
    "    <li><b>Mean Squared Error (MSE)</b> => measures the average of the squares of errors, that is, the difference between actual value (y) and the estimated value (Å·)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2\n",
    "lm.fit(df[['horsepower_fit']], df['price'])\n",
    "# Find the R^2\n",
    "print('The R-square is: ', lm.score(X, Y)) # 0.760xxxx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R^2 alternatives\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y, p(x))\n",
    "print('The R-square value is: ', r_squared) # <- the close to -1/1 the better, the closer to zero = bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say 76% of the variation of the price is explained by the simple linear model \"horsepower_fit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets calculate the MSE\n",
    "Yhat=lm.predict(X)\n",
    "print('The output of the first four predicted value is: ', Yhat[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(df['price'], Yhat)\n",
    "print('The mean square error of price and predicted value is: ', mse) #15021126.025174143 <- the smaller the better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Decision Making\n",
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new input\n",
    "new_input=np.arange(1, 100, 1).reshape(-1, 1)\n",
    "\n",
    "#fit the model\n",
    "lm.fit(X, Y)\n",
    "lm\n",
    "\n",
    "#produce a prediction\n",
    "yhat=lm.predict(new_input)\n",
    "yhat[0:5]\n",
    "\n",
    "#plot a data\n",
    "plt.plot(new_input, yhat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"prediction_to_predict.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Making\n",
    "Even tho multiple models usually results better, we need to check the MSE and R^2 to convinced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting\n",
    "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
    "    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n",
    "\n",
    "    plt.title(Title)\n",
    "    plt.xlabel('Price (in dollars)')\n",
    "    plt.ylabel('Proportion of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    \n",
    "    #training data \n",
    "    #testing data \n",
    "    # lr:  linear regression object \n",
    "    #poly_transform:  polynomial transformation object \n",
    " \n",
    "    xmax=max([xtrain.values.max(), xtest.values.max()])\n",
    "\n",
    "    xmin=min([xtrain.values.min(), xtest.values.min()])\n",
    "\n",
    "    x=np.arange(xmin, xmax, 0.1)\n",
    "\n",
    "\n",
    "    plt.plot(xtrain, y_train, 'ro', label='Training Data')\n",
    "    plt.plot(xtest, y_test, 'go', label='Test Data')\n",
    "    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Predicted Function')\n",
    "    plt.ylim([-10000, 60000])\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_data = df['price']\n",
    "x_data=df.drop('price',axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.10, random_state=1)\n",
    "\n",
    "print(\"number of test samples :\", x_test.shape[0])\n",
    "print(\"number of training samples:\",x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#create model\n",
    "lre=LinearRegression()\n",
    "\n",
    "#train\n",
    "lre.fit(x_train[['horsepower']], y_train)\n",
    "\n",
    "#check r^2\n",
    "lre.score(x_test[['horsepower']], y_test)\n",
    "lre.score(x_train[['horsepower']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the bigger the train test is, the better accuracy it will get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=4)\n",
    "Rcross\n",
    "print(\"The mean of the folds are\", Rcross.mean(), \"and the standard deviation is\" , Rcross.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fyi\n",
    "#We can use negative squared error as a score by setting the parameter  'scoring' metric to 'neg_mean_squared_error'. \n",
    "\n",
    "-1 * cross_val_score(lre,x_data[['horsepower']], y_data,cv=4,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fyi, you can crossval output prediction\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "yhat = cross_val_predict(lre,x_data[['horsepower']], y_data,cv=4)\n",
    "\n",
    "#returning array\n",
    "yhat[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting, Underfitting, and Model Selection\n",
    "When it has good score for sample data but not in the real world.\n",
    "> This problem has higher chance in MLR and Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_train)\n",
    "\n",
    "yhat_train = lr.predict(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "yhat_train[0:5]\n",
    "\n",
    "yhat_test = lr.predict(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])\n",
    "yhat_test[0:5]\n",
    "\n",
    "#the train and test prediction has a very different score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check overfitting by plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\n",
    "DistributionPlot(y_train, yhat_train, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Good Model</p>\n",
    "<img src=\"./overfit_plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to predict with prediction test (smaller dataset)\n",
    "Title='Distribution  Plot of  Predicted Value Using Test Data vs Data Distribution of Test Data'\n",
    "DistributionPlot(y_test,yhat_test,\"Actual Values (Test)\",\"Predicted Values (Test)\",Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"> Overfitted </p>\n",
    "<img src=\"./overfit_plot_bad.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting on polynomial\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.45, random_state=0)\n",
    "\n",
    "pr = PolynomialFeatures(degree=5)\n",
    "x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "pr\n",
    "\n",
    "poly = LinearRegression()\n",
    "poly.fit(x_train_pr, y_train)\n",
    "\n",
    "yhat = poly.predict(x_test_pr)\n",
    "yhat[0:5]\n",
    "\n",
    "print(\"Predicted values:\", yhat[0:4])\n",
    "print(\"True values:\", y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train, y_test, poly,pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./overfit_plot_bad.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check R^2\n",
    "poly.score(x_train_pr, y_train) #0.556\n",
    "poly.score(x_test_pr, y_test) #-29.871, negative indicates overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the right Polynomial Degree through plot\n",
    "Rsqu_test = []\n",
    "\n",
    "order = [1, 2, 3, 4]\n",
    "for n in order:\n",
    "    pr = PolynomialFeatures(degree=n)\n",
    "    \n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    \n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])    \n",
    "    \n",
    "    lr.fit(x_train_pr, y_train)\n",
    "    \n",
    "    Rsqu_test.append(lr.score(x_test_pr, y_test))\n",
    "\n",
    "plt.plot(order, Rsqu_test)\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('R^2')\n",
    "plt.title('R^2 Using Test Data')\n",
    "plt.text(3, 0.75, 'Maximum R^2 ')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">See the crest, usually it's the best</p>\n",
    "<img src=\"./polynomial_degree_plot.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERACTIVE MATPLOTLIB!!!!\n",
    "def f(order, test_data):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=test_data, random_state=0)\n",
    "    pr = PolynomialFeatures(degree=order)\n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "    poly = LinearRegression()\n",
    "    poly.fit(x_train_pr,y_train)\n",
    "    PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train,y_test, poly, pr)\n",
    "    \n",
    "interact(f, order=(0, 6, 1), test_data=(0.05, 0.95, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "How alpha parameter changes the model. Notes: test data here is just for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PolynomialFeatures(degree=2)\n",
    "x_train_pr=pr.fit_transform(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg','normalized-losses','symboling']])\n",
    "x_test_pr=pr.fit_transform(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg','normalized-losses','symboling']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#set the regularization parameter to 0.1\n",
    "RigeModel=Ridge(alpha=0.1)\n",
    "# fit the model\n",
    "RigeModel.fit(x_train_pr, y_train)\n",
    "#obtain prediction\n",
    "yhat = RigeModel.predict(x_test_pr)\n",
    "\n",
    "print('predicted:', yhat[0:4])\n",
    "print('test set :', y_test[0:4].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the alpha that minimizes the test error using loop\n",
    "Rsqu_test = []\n",
    "Rsqu_train = []\n",
    "dummy1 = []\n",
    "Alpha = 10 * np.array(range(0,1000))\n",
    "for alpha in Alpha:\n",
    "    RigeModel = Ridge(alpha=alpha) \n",
    "    RigeModel.fit(x_train_pr, y_train)\n",
    "    Rsqu_test.append(RigeModel.score(x_test_pr, y_test))\n",
    "    Rsqu_train.append(RigeModel.score(x_train_pr, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out the value of r^2\n",
    "width = 12\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(Alpha,Rsqu_test, label='validation data  ')\n",
    "plt.plot(Alpha,Rsqu_train, 'r', label='training Data ')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ridge.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set hyperparameter\n",
    "parameters1= [{'alpha': [0.001,0.1,1, 10, 100, 1000, 10000, 100000, 100000]}]\n",
    "parameters1\n",
    "\n",
    "#initialise model\n",
    "RR=Ridge()\n",
    "RR\n",
    "\n",
    "#create a  ridge grid search object\n",
    "Grid1 = GridSearchCV(RR, parameters1,cv=4)\n",
    "\n",
    "#fit the model\n",
    "Grid1.fit(x_data[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_data)\n",
    "\n",
    "#let the grid search find the best estimator value\n",
    "BestRR=Grid1.best_estimator_\n",
    "BestRR\n",
    "\n",
    "#print the highest value from the various hyperparameter\n",
    "BestRR.score(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
